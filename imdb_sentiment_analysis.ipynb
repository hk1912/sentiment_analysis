{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras as K\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  # 0. get started\n",
    "  print(\"\\nIMDB sentiment analysis using Keras/TensorFlow \")\n",
    "  np.random.seed(1)\n",
    "  tf.set_random_seed(1)\n",
    "\n",
    "  # 1. load data\n",
    "  max_words = 20000\n",
    "  print(\"Loading data, max unique words = %d words\\n\" % max_words)\n",
    "  (train_x, train_y), (test_x, test_y) = \\\n",
    "    K.datasets.imdb.load_data(seed=1, num_words=max_words)\n",
    "\n",
    "  max_review_len = 80\n",
    "  train_x = K.preprocessing.sequence.pad_sequences(train_x,\n",
    "    truncating='pre', padding='pre', maxlen=max_review_len)  # pad and chop!\n",
    "  test_x = K.preprocessing.sequence.pad_sequences(test_x,\n",
    "    truncating='pre', padding='pre', maxlen=max_review_len)\n",
    "  \n",
    "  # 2. define model\n",
    "  print(\"Creating LSTM model\")\n",
    "  e_init = K.initializers.RandomUniform(-0.01, 0.01, seed=1)\n",
    "  init = K.initializers.glorot_uniform(seed=1)\n",
    "  simple_adam = K.optimizers.Adam()\n",
    "  embed_vec_len = 32  # values per word -- 100-500 is typical\n",
    "\n",
    "  model = K.models.Sequential()\n",
    "  model.add(K.layers.embeddings.Embedding(input_dim=max_words,\n",
    "    output_dim=embed_vec_len, embeddings_initializer=e_init,\n",
    "    mask_zero=True))\n",
    "  model.add(K.layers.LSTM(units=100, kernel_initializer=init,\n",
    "    dropout=0.2, recurrent_dropout=0.2))  # 100 memory\n",
    "  model.add(K.layers.Dense(units=1, kernel_initializer=init,\n",
    "    activation='sigmoid'))\n",
    "  model.compile(loss='binary_crossentropy', optimizer=simple_adam,\n",
    "    metrics=['acc'])\n",
    "\n",
    "  print(model.summary()) \n",
    "  bat_size = 32\n",
    "  max_epochs = 3\n",
    "  print(\"\\nStarting training \")\n",
    "  model.fit(train_x, train_y, epochs=max_epochs,\n",
    "    batch_size=bat_size, shuffle=True, verbose=1) \n",
    "  print(\"Training complete \\n\")\n",
    "\n",
    "  # 4. evaluate model\n",
    "  loss_acc = model.evaluate(test_x, test_y, verbose=0)\n",
    "  print(\"Test data: loss = %0.6f  accuracy = %0.2f%% \" % \\\n",
    "    (loss_acc[0], loss_acc[1]*100))\n",
    "\n",
    "  # 5. save model\n",
    "  \n",
    "  model.save('mp.h5')  \n",
    "\n",
    "  # 6. use model\n",
    "  print(\"New review: \\'the movie was a great waste of my time\\'\")\n",
    "  d = K.datasets.imdb.get_word_index()\n",
    "  review = \"the movie was a great waste of my time\"\n",
    "  words = review.split()\n",
    "  review = []\n",
    "  for word in words:\n",
    "    if word not in d: \n",
    "      review.append(2)\n",
    "    else:\n",
    "      review.append(d[word]+3)\n",
    "  review = K.preprocessing.sequence.pad_sequences([review],\n",
    "    truncating='pre',  padding='pre', maxlen=max_review_len)\n",
    "\n",
    "  prediction = model.predict(review)\n",
    "  print(\"Prediction (0 = negative, 1 = positive) = \", end=\"\")\n",
    "  print(\"%0.4f\" % prediction[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMDB sentiment analysis using Keras/TensorFlow \n",
      "Loading data, max unique words = 20000 words\n",
      "\n",
      "Creating LSTM model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 32)          640000    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 693,301\n",
      "Trainable params: 693,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Starting training \n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 82s 3ms/step - loss: 0.4659 - acc: 0.7788\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 77s 3ms/step - loss: 0.3158 - acc: 0.8724\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 78s 3ms/step - loss: 0.2510 - acc: 0.9025\n",
      "Training complete \n",
      "\n",
      "Test data: loss = 0.418549  accuracy = 81.31% \n",
      "New review: 'the movie was a great waste of my time'\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 4s 3us/step\n",
      "Prediction (0 = negative, 1 = positive) = 0.1076\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
